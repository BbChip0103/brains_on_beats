{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brains_on_beats_model_test",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "-fWomgC-kF5f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Architecture **\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=12JomC2IswVbNGdE0IIvPpUk8vPjP-MBQ\"  alt=\"artchtecture\">\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jCP47cJgna91",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Figure 1: Architecture of the one-stream models. First seven layers are followed by parametric\n",
        "softplus units [25], and the last layer is followed by sigmoid units. The architecture is similar to that\n",
        "of AlexNet [26] except for the following modifications: (i) The number of convolutional kernels\n",
        "are halved. (ii) The (convolutional and pooling) kernels and strides are flattened. That is, an n \u0002 n\n",
        "kernel is changed to an n2 \u0002 1 kernel and an m \u0002 m stride is changed to an m2 \u0002 1 stride. (iii)\n",
        "Local response normalization is replaced with batch normalization [27]. (iv) Rectified linear units are\n",
        "replaced with parametric softplus units with initial \u000b = 0.2 and initial \f = 0.5. (v) Softmax units are\n",
        "replaced with sigmoid units.\n",
        "\n",
        "We used Adam [28] with parameters \u000b = 0:0002, \f1 = 0:5, \f2 = 0:999, \u000f = 1eô€€€8 and a mini batch\n",
        "size of 36 to train the models by minimizing the binary cross-entropy loss function. Initial model\n",
        "parameters were drawn from a uniform distribution as described in [29]. Songs in each training\n",
        "mini-batch were randomly cropped to six seconds (96000 samples). The epoch in which the validation\n",
        "performance was the highest was taken as the final model (53, 12 and 12 for T, F and TF models,\n",
        "respectively). The DNN models were implemented in Keras [30].\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uN7hQRZsDbgI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(1) Importing dependency"
      ]
    },
    {
      "metadata": {
        "id": "3lPxjI5BDAkX",
        "colab_type": "code",
        "outputId": "88280284-3c51-485b-adfa-4c428507fb92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        "                         Conv1D, MaxPooling1D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "py5KMVLnDZsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(2) Get Data"
      ]
    },
    {
      "metadata": {
        "id": "bWFB1X_4DWyK",
        "colab_type": "code",
        "outputId": "4882f32e-10cd-4400-db3b-c5c0cae5f263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# x, y = oxflower17.load_data(one_hot=True)\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,\n",
        "#                                                     random_state=42)\n",
        "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "\n",
        "# code test setting\n",
        "input_shape = (96000, 1)\n",
        "\n",
        "sample_x = np.zeros([100]+list(input_shape))\n",
        "sample_y = np.zeros([100]+[50])\n",
        "\n",
        "print(sample_x.shape, sample_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 96000, 1) (100, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "12cS85jvDnfS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(3) Create a sequential model"
      ]
    },
    {
      "metadata": {
        "id": "4GDedqMJcJYr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define Parametric Softplus\n",
        "\n",
        "# alpha * log(1 + exp(beta * x))\n",
        "def ParametricSoftplus(alpha=0.2, beta=5.0):\n",
        "  return lambda x: alpha * keras.activations.softplus(beta * x)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fs8Heys2Dm30",
        "colab_type": "code",
        "outputId": "bad14ede-be9c-4a2f-d052-9d9a29a5e437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        }
      },
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "\n",
        "# 1st Convolutional Layer (conv1)\n",
        "model.add(Conv1D (kernel_size=121, filters=48, strides=16, padding='same',\n",
        "                  input_shape=input_shape))\n",
        "model.add(Activation(ParametricSoftplus(alpha=0.2, beta=0.5)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Pooling (pool1)\n",
        "model.add(MaxPooling1D(pool_size=9, strides=4, padding='same'))\n",
        "\n",
        "# 2nd Convolutional Layer (conv2)\n",
        "model.add(Conv1D (kernel_size=25, filters=128, padding='same'))\n",
        "model.add(Activation(ParametricSoftplus(alpha=0.2, beta=0.5)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Pooling (pool2)\n",
        "model.add(MaxPooling1D(pool_size=9, strides=4, padding='same'))\n",
        "\n",
        "# 3rd Convolutional Layer (conv3)\n",
        "model.add(Conv1D (kernel_size=9, filters=192, padding='same'))\n",
        "model.add(Activation(ParametricSoftplus(alpha=0.2, beta=0.5)))\n",
        "\n",
        "# 4rd Convolutional Layer (conv4)\n",
        "model.add(Conv1D (kernel_size=9, filters=192, padding='same'))\n",
        "model.add(Activation(ParametricSoftplus(alpha=0.2, beta=0.5)))\n",
        "\n",
        "# 5rd Convolutional Layer (conv5)\n",
        "model.add(Conv1D (kernel_size=9, filters=128, padding='same'))\n",
        "model.add(Activation(ParametricSoftplus(alpha=0.2, beta=0.5)))\n",
        "\n",
        "# Pooling (pool5)\n",
        "model.add(MaxPooling1D(pool_size=9, strides=4, padding='same'))\n",
        "\n",
        "# 1st Dense Layer (full6)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation(ParametricSoftplus(alpha=0.2, beta=0.5)))\n",
        "model.add(Dropout(0.5)) # Drop-out value is not specified in the paper\n",
        "\n",
        "# 2nd Dense Layer (full7)\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation(ParametricSoftplus(alpha=0.2, beta=0.5)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer (full8)\n",
        "model.add(Dense(50))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 6000, 48)          5856      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 6000, 48)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 6000, 48)          192       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 1500, 48)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1500, 128)         153728    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1500, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1500, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 375, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 375, 192)          221376    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 375, 192)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 375, 192)          331968    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 375, 192)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 375, 128)          221312    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 375, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 94, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12032)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              49287168  \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                204850    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 50)                0         \n",
            "=================================================================\n",
            "Total params: 67,208,274\n",
            "Trainable params: 67,207,922\n",
            "Non-trainable params: 352\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RLxfqHNxDuJq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(4) Compile "
      ]
    },
    {
      "metadata": {
        "id": "5jPB8IbZDxeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adam_with_params = keras.optimizers.Adam(lr=0.0002, beta_1=0.1, beta_2=0.999, \n",
        "                                         epsilon=1e-8)\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam_with_params,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VUsuRj-7Dzxx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(5) Train"
      ]
    },
    {
      "metadata": {
        "id": "ZUVV71K2D2tZ",
        "colab_type": "code",
        "outputId": "7a454152-003e-4615-acd8-cfdb60ef8170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(sample_x, sample_y, batch_size=36, epochs=10, verbose=1, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 0.6069 - acc: 0.7395 - val_loss: 0.4013 - val_acc: 1.0000\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.3568 - acc: 0.9983 - val_loss: 0.1792 - val_acc: 1.0000\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.1440 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 1.0000\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 9.0676e-04 - val_acc: 1.0000\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 6.5382e-04 - val_acc: 1.0000\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 8.7042e-04 - acc: 1.0000 - val_loss: 4.9586e-04 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b7ef03128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "DefsBoWAFKdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# %time pred = model.predict_classes(np.expand_dims(x_test[0], axis=0))\n",
        "# print('Predict:', pred)\n",
        "\n",
        "# [loss, accuracy] = model.evaluate(x_test, y_test)\n",
        "# print('Loss:', loss, 'Accuracy:', accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}